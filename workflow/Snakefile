import os
import sys
import math
from snakemake.utils import min_version

min_version("7.32.2")


report: "report/workflow.rst"


# Configuration
configfile: ".test/config.yaml"


# Variables
REFIDS = config["references"].keys()


wildcard_constraints:
    refid="|".join(REFIDS),


# Default rule
rule all:
    input:
        expand(
            "results/{refid}.adotto_TRregions_v1.0.bed",
            refid=REFIDS,
        ),


## General Rules --------------------------------------------------------------
# - rules for sorting, compressing, and indexing files
rule samtools_index:
    input:
        "{prefix}.fasta.gz",
    output:
        "{prefix}.fasta.gz.fai",
    log:
        "logs/samtools_index/{prefix}.log",
    wrapper:
        "v2.6.0/bio/samtools/faidx"


def get_ref_fai(wildcards):
    ref = wildcards.get("ref", "")
    if ref:
        ref_id = ref
    else:
        ref_id = wildcards.get("ref_id", "")
        if not ref_id:
            prefix = wildcards.get("prefix", "")
            for id in REFIDS:
                if id in prefix:
                    ref_id = id
    if not ref_id:
        print(f"ref_id could not be determined from wildcards or {prefix}")

    return f"results/{ref_id}.fasta.gz.fai"


rule bedtools_sort_bed:
    input:
        in_file="{prefix}.bed",
        genome=get_ref_fai,
    output:
        "{prefix}_sorted.bed",
    log:
        "logs/sort_bed/{prefix}.log",
    wrapper:
        "v2.6.0/bio/bedtools/sort"


rule bgzip:
    input:
        "{prefix}.bed",
    output:
        "{prefix}.bed.gz",
    threads: 1
    log:
        "logs/bgzip/{prefix}.log",
    wrapper:
        "v2.6.0/bio/bgzip"


rule tabix:
    input:
        "{prefix}.bed.gz",
    output:
        "{prefix}.bed.gz.tbi",
    log:
        "logs/tabix/{prefix}.log",
    params:
        "-p bed",
    wrapper:
        "v2.6.0/bio/tabix/index"


rule create_genome_file:
    input:
        fai="{prefix}.fasta.fai",
    output:
        genome="{prefix}.genome",
    log:
        "logs/create_genome_file/{prefix}.log",
    conda:
        "envs/download.yml"
    shell:
        """
        # Extract the first two columns (chromosome and size) from the .fai file
        cut -f 1,2 {input.fai} 1> {output.genome} 2> {log}
        """


## Downloading resources ------------------------------------------------------
# Rule to download the reference genome
rule download_reference:
    output:
        "results/{refid}.fasta.gz",
    params:
        refurl=lambda wildcards: config["references"][wildcards.refid]["REFURL"],
        expected_md5=lambda wildcards: config["references"][wildcards.refid]["REF_MD5"],
    log:
        "logs/{refid}_download_reference.log",
    conda:
        "envs/download.yml"
    shell:
        """
        curl -L {params.refurl} 1> {output} 2> {log}
        echo "{params.expected_md5}  {output}" | md5sum -c - &>> {log}
        """


# Rule to download GIAB TR stratification
rule download_giab_tr:
    output:
        "results/{refid}.tr_regions.bed.gz",
    params:
        giabtrurl=lambda wildcards: config["references"][wildcards.refid]["GIABTRURL"],
        expected_md5=lambda wildcards: config["references"][wildcards.refid][
            "GIABTR_MD5"
        ],
    log:
        "logs/{refid}_download_giab_tr.log",
    conda:
        "envs/download.yml"
    shell:
        """
        curl -L {params.giabtrurl} 1> {output} 2> {log}
        echo "{params.expected_md5}  {output}" | md5sum -c - &>> {log}
        """


## TR Region Stats and Pre-Processing -----------------------------------------
## Summary stats for region (span) size distribution
### https://github.com/ACEnglish/adotto/blob/main/regions/scripts/bed_stats.py
rule span_stats:
    input:
        bed="results/{refid}.tr_regions.bed.gz",
    output:
        stats="results/{refid}.tr_regions_span_stats.txt",
    log:
        "logs/{refid}.tr_regions_span_stats.log",
    conda:
        "envs/span_stats.yml"
    shell:
        """
        zcat {input.bed} \
            | python workflow/scripts/bed_stats.py \
            1> {output.stats} 2> {log}
    """


## Filtering Regions
## - removing regions from extra chromosomes, regions lt 50 bp and gt 50kb
## - follows methods used to generate Adotto DB v1.0
## https://github.com/ACEnglish/adotto/blob/main/regions/scripts/merged_bed_filter.py
rule filter_regions:
    input:
        bed="results/{refid}.tr_regions.bed.gz",
    output:
        bed="results/{refid}.tr_regions_filtered.bed",
        stats="results/{refid}.tr_regions_filter_stats.json",
    log:
        "logs/{refid}.tr_regions_filter_regions.log",
    conda:
        "envs/span_stats.yml"
    shell:
        """
        zcat {input.bed} \
            | python workflow/scripts/filter_tr_regions.py \
            {output.stats} 1> {output.bed} 2> {log}
    """


rule bedtools_slop:
    input:
        "results/{refid}.tr_regions_filtered.bed",
        genome="results/{refid}.genome",
    output:
        "results/{refid}.tr_regions_filtered_slop25.bed",
    params:
        ## Genome file, tab-seperated file defining the length of every contig
        genome="results/{refid}.genome",
        extra="-b 25",
    log:
        "logs/slop/{refid}.tr_regions_filtered_slop25.log",
    wrapper:
        "v2.6.0/bio/bedtools/slop"


## TRF Annotations ------------------------------------------------------------
# Rule to get repeat sequences using samtools
rule get_repeat_sequences:
    input:
        bed="results/{refid}.tr_regions_filtered_slop25.bed",
        ref="results/{refid}.fasta.gz",
    output:
        "results/{refid}.tr_sequences.fasta",
    log:
        "logs/{refid}_get_repeat_sequences.log",
    conda:
        "envs/samtools.yml"
    shell:
        """
       awk '{{print $1 ":" $2 "-" $3}}' {input.bed} 2>> {log} \
            | samtools faidx {input.ref} -r - \
            1> {output} 2>> {log}
        """


# Rule to annotate sequences using trf
rule annotate_sequences:
    input:
        "results/{refid}.tr_sequences.fasta",
    output:
        "results/{refid}.tandemrepeatfinder.txt",
    log:
        "logs/{refid}_annotate_sequences.log",
    conda:
        "envs/trf.yml"
    shell:
        "trf {input} 3 7 7 80 5 5 500 -h -ngs 1> {output} 2>{log}"


# Rule for TRF parsing
rule trf_parsing:
    input:
        "results/{refid}.tandemrepeatfinder.txt",
    output:
        "results/{refid}.trf_annos.bed",
    log:
        "logs/{refid}.trf_parsing.log",
    conda:
        "envs/trf_reformatter.yml"
    shell:
        """
        python workflow/scripts/trf_reformatter.py {input} {output} > {log}
        """


## TODO - add rule for TRF intersection
## - intersect trf_annos back to the input sources for QC
## - will need to modify for single source and replace/ fix hard coded paths
## https://github.com/ACEnglish/adotto/blob/main/regions/scripts/bed_intersection_stats.py


rule trf_intersection:
    input:
        tr="results/{refid}.tr_regions_filtered.bed",
        trannos="results/{refid}.trf_annos.bed",
    output:
        "results/{refid}.intersection.jl",
    log:
        "logs/{refid}.trf_intersection.log",
    conda:
        "envs/annotation_improver.yml"
    shell:
        """
        python scripts/bed_intersection_stats.py {input.tr} {input.trannos} &> {log}
    """


## TODO - add rule to QC TRF annotations
## -- will need to fix hard coded paths and modify as necessary to work within snakemake
## https://github.com/ACEnglish/adotto/blob/main/regions/notebooks/analysis.ipynb


# Rule for identifying unannotated regions
rule unannotated_regions:
    input:
        regions="results/{refid}.tr_regions_filtered_slop25.bed",
        annotated="results/{refid}.trf_annos.bed",
    output:
        "results/{refid}.unannotated_regions.bed",
    log:
        "logs/{refid}_unannotated_regions.log",
    conda:
        "envs/bedtools.yml"
    shell:
        """
        bedtools intersect -a {input.regions} -b {input.annotated} -c 2> {log}\
            | awk '$4 == 0' 1> {output} 2>> {log}
        """


# Rule for intermediate annotations
rule intermediate_annotations:
    input:
        regions="results/{refid}.tr_regions_filtered_slop25.bed",
        regions_tbi="results/{refid}.tr_regions.bed.gz.tbi",
        annotations="results/{refid}.trf_annos_sorted.bed.gz",
        annotations_tbi="results/{refid}.trf_annos_sorted.bed.gz.tbi",
    output:
        bed="results/{refid}.candidate_v1.0.bed",
    log:
        "logs/{refid}_intermediate_annotations.log",
    conda:
        "envs/intermediate_annotations.yml"
    shell:
        """
        python workflow/scripts/tr_reganno_maker.py \
            {input.regions} {input.annotations}  \
            1> {output.bed} 2> {log}
        """


## RepeatMasker Annotations ---------------------------------------------------
# Rule for splitting fasta into multiple parts
rule split_fasta:
    input:
        fasta="results/{refid}.tr_sequences.fasta",
    output:
        expand(
            "results/split_fasta_parts/{{refid}}.part{part}.fasta",
            part=range(config["n_splits"]),
        ),
    params:
        n_parts=config["n_splits"],
        refid="{refid}",
        outdir="results/split_fasta_parts/",
    log:
        "logs/{refid}_split_fasta.log",
    conda:
        "envs/fasta_splitter.yml"
    shell:
        """
        python workflow/scripts/fasta_splitter.py \
            --fasta_path {input.fasta} \
            --n_parts {params.n_parts} \
            --output_dir {params.outdir} \
            --refid {params.refid} \
            &> {log}
        """


# Rule for creating RepeatMasker annotations
rule repeatmasker_annotations:
    input:
        split_fasta="results/split_fasta_parts/{refid}.part{part}.fasta",
    output:
        annotated="results/repeatmasker_annotated/{refid}/{refid}.part{part}.fasta.out",
    log:
        "logs/{refid}_repeatmasker_part{part}.log",
    params:
        outdir="results/repeatmasker_annotated/{refid}/",
    threads: config["rm_threads"]
    conda:
        "envs/repeatmasker.yml"
    shell:
        """
        RepeatMasker \
            -pa {threads} \
            -qq -e hmmer -species human -lcambig -nocut -div 50 -no_id \
            -dir {params.outdir} \
            -s {input.split_fasta} &> {log}
        """


# Rule to convert RepeatMasker Output to joblib
rule convert_repeatmasker_to_joblib:
    input:
        rmout_files=expand(
            "results/repeatmasker_annotated/{{refid}}/{{refid}}.part{part}.fasta.out",
            part=range(config["n_splits"]),
        ),
    output:
        "results/{refid}.repmask.jl",
    log:
        "logs/{refid}_convert_repeatmasker.log",
    conda:
        "envs/repmask_to_joblib.yml"
    shell:
        """
        python workflow/scripts/repmask_to_joblib.py {input.rmout_files} 2> {log}
        mv repmask_results.dict.jl {output}
        """


## Building Adotto Formatted Tandem Repeat Database ---------------------------
# Rule for improving annotations
rule improve_annotations:
    input:
        candidate="results/{refid}.candidate_v1.0_sorted.bed.gz",
        reference="results/{refid}.fasta.gz",
        repmask="results/{refid}.repmask.jl",
    output:
        "results/{refid}.adotto_TRregions_v1.0.bed",
    log:
        "logs/{refid}_improve_annotations.log",
    conda:
        "envs/annotation_improver.yml"
    shell:
        """
        python workflow/scripts/annotation_improver.py \
            {input.candidate} \
            {input.reference} \
            {input.repmask} \
            1> {output} 2> {log}
        """
